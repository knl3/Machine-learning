{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Private</th>\n",
       "      <th>Apps</th>\n",
       "      <th>Accept</th>\n",
       "      <th>Enroll</th>\n",
       "      <th>Top10perc</th>\n",
       "      <th>Top25perc</th>\n",
       "      <th>F.Undergrad</th>\n",
       "      <th>P.Undergrad</th>\n",
       "      <th>Outstate</th>\n",
       "      <th>Room.Board</th>\n",
       "      <th>Books</th>\n",
       "      <th>Personal</th>\n",
       "      <th>PhD</th>\n",
       "      <th>Terminal</th>\n",
       "      <th>S.F.Ratio</th>\n",
       "      <th>perc.alumni</th>\n",
       "      <th>Expend</th>\n",
       "      <th>Grad.Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yes</td>\n",
       "      <td>1660</td>\n",
       "      <td>1232</td>\n",
       "      <td>721</td>\n",
       "      <td>23</td>\n",
       "      <td>52</td>\n",
       "      <td>2885</td>\n",
       "      <td>537</td>\n",
       "      <td>7440</td>\n",
       "      <td>3300</td>\n",
       "      <td>450</td>\n",
       "      <td>2200</td>\n",
       "      <td>70</td>\n",
       "      <td>78</td>\n",
       "      <td>18.1</td>\n",
       "      <td>12</td>\n",
       "      <td>7041</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yes</td>\n",
       "      <td>2186</td>\n",
       "      <td>1924</td>\n",
       "      <td>512</td>\n",
       "      <td>16</td>\n",
       "      <td>29</td>\n",
       "      <td>2683</td>\n",
       "      <td>1227</td>\n",
       "      <td>12280</td>\n",
       "      <td>6450</td>\n",
       "      <td>750</td>\n",
       "      <td>1500</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>12.2</td>\n",
       "      <td>16</td>\n",
       "      <td>10527</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yes</td>\n",
       "      <td>1428</td>\n",
       "      <td>1097</td>\n",
       "      <td>336</td>\n",
       "      <td>22</td>\n",
       "      <td>50</td>\n",
       "      <td>1036</td>\n",
       "      <td>99</td>\n",
       "      <td>11250</td>\n",
       "      <td>3750</td>\n",
       "      <td>400</td>\n",
       "      <td>1165</td>\n",
       "      <td>53</td>\n",
       "      <td>66</td>\n",
       "      <td>12.9</td>\n",
       "      <td>30</td>\n",
       "      <td>8735</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yes</td>\n",
       "      <td>417</td>\n",
       "      <td>349</td>\n",
       "      <td>137</td>\n",
       "      <td>60</td>\n",
       "      <td>89</td>\n",
       "      <td>510</td>\n",
       "      <td>63</td>\n",
       "      <td>12960</td>\n",
       "      <td>5450</td>\n",
       "      <td>450</td>\n",
       "      <td>875</td>\n",
       "      <td>92</td>\n",
       "      <td>97</td>\n",
       "      <td>7.7</td>\n",
       "      <td>37</td>\n",
       "      <td>19016</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yes</td>\n",
       "      <td>193</td>\n",
       "      <td>146</td>\n",
       "      <td>55</td>\n",
       "      <td>16</td>\n",
       "      <td>44</td>\n",
       "      <td>249</td>\n",
       "      <td>869</td>\n",
       "      <td>7560</td>\n",
       "      <td>4120</td>\n",
       "      <td>800</td>\n",
       "      <td>1500</td>\n",
       "      <td>76</td>\n",
       "      <td>72</td>\n",
       "      <td>11.9</td>\n",
       "      <td>2</td>\n",
       "      <td>10922</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>No</td>\n",
       "      <td>2197</td>\n",
       "      <td>1515</td>\n",
       "      <td>543</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>3089</td>\n",
       "      <td>2029</td>\n",
       "      <td>6797</td>\n",
       "      <td>3900</td>\n",
       "      <td>500</td>\n",
       "      <td>1200</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>21.0</td>\n",
       "      <td>14</td>\n",
       "      <td>4469</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>Yes</td>\n",
       "      <td>1959</td>\n",
       "      <td>1805</td>\n",
       "      <td>695</td>\n",
       "      <td>24</td>\n",
       "      <td>47</td>\n",
       "      <td>2849</td>\n",
       "      <td>1107</td>\n",
       "      <td>11520</td>\n",
       "      <td>4960</td>\n",
       "      <td>600</td>\n",
       "      <td>1250</td>\n",
       "      <td>73</td>\n",
       "      <td>75</td>\n",
       "      <td>13.3</td>\n",
       "      <td>31</td>\n",
       "      <td>9189</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>Yes</td>\n",
       "      <td>2097</td>\n",
       "      <td>1915</td>\n",
       "      <td>695</td>\n",
       "      <td>34</td>\n",
       "      <td>61</td>\n",
       "      <td>2793</td>\n",
       "      <td>166</td>\n",
       "      <td>6900</td>\n",
       "      <td>4200</td>\n",
       "      <td>617</td>\n",
       "      <td>781</td>\n",
       "      <td>67</td>\n",
       "      <td>75</td>\n",
       "      <td>14.4</td>\n",
       "      <td>20</td>\n",
       "      <td>8323</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>Yes</td>\n",
       "      <td>10705</td>\n",
       "      <td>2453</td>\n",
       "      <td>1317</td>\n",
       "      <td>95</td>\n",
       "      <td>99</td>\n",
       "      <td>5217</td>\n",
       "      <td>83</td>\n",
       "      <td>19840</td>\n",
       "      <td>6510</td>\n",
       "      <td>630</td>\n",
       "      <td>2115</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>5.8</td>\n",
       "      <td>49</td>\n",
       "      <td>40386</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>Yes</td>\n",
       "      <td>2989</td>\n",
       "      <td>1855</td>\n",
       "      <td>691</td>\n",
       "      <td>28</td>\n",
       "      <td>63</td>\n",
       "      <td>2988</td>\n",
       "      <td>1726</td>\n",
       "      <td>4990</td>\n",
       "      <td>3560</td>\n",
       "      <td>500</td>\n",
       "      <td>1250</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>18.1</td>\n",
       "      <td>28</td>\n",
       "      <td>4509</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>777 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Private   Apps  Accept  Enroll  Top10perc  Top25perc  F.Undergrad  \\\n",
       "0       Yes   1660    1232     721         23         52         2885   \n",
       "1       Yes   2186    1924     512         16         29         2683   \n",
       "2       Yes   1428    1097     336         22         50         1036   \n",
       "3       Yes    417     349     137         60         89          510   \n",
       "4       Yes    193     146      55         16         44          249   \n",
       "..      ...    ...     ...     ...        ...        ...          ...   \n",
       "772      No   2197    1515     543          4         26         3089   \n",
       "773     Yes   1959    1805     695         24         47         2849   \n",
       "774     Yes   2097    1915     695         34         61         2793   \n",
       "775     Yes  10705    2453    1317         95         99         5217   \n",
       "776     Yes   2989    1855     691         28         63         2988   \n",
       "\n",
       "     P.Undergrad  Outstate  Room.Board  Books  Personal  PhD  Terminal  \\\n",
       "0            537      7440        3300    450      2200   70        78   \n",
       "1           1227     12280        6450    750      1500   29        30   \n",
       "2             99     11250        3750    400      1165   53        66   \n",
       "3             63     12960        5450    450       875   92        97   \n",
       "4            869      7560        4120    800      1500   76        72   \n",
       "..           ...       ...         ...    ...       ...  ...       ...   \n",
       "772         2029      6797        3900    500      1200   60        60   \n",
       "773         1107     11520        4960    600      1250   73        75   \n",
       "774          166      6900        4200    617       781   67        75   \n",
       "775           83     19840        6510    630      2115   96        96   \n",
       "776         1726      4990        3560    500      1250   75        75   \n",
       "\n",
       "     S.F.Ratio  perc.alumni  Expend  Grad.Rate  \n",
       "0         18.1           12    7041         60  \n",
       "1         12.2           16   10527         56  \n",
       "2         12.9           30    8735         54  \n",
       "3          7.7           37   19016         59  \n",
       "4         11.9            2   10922         15  \n",
       "..         ...          ...     ...        ...  \n",
       "772       21.0           14    4469         40  \n",
       "773       13.3           31    9189         83  \n",
       "774       14.4           20    8323         49  \n",
       "775        5.8           49   40386         99  \n",
       "776       18.1           28    4509         99  \n",
       "\n",
       "[777 rows x 18 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection  import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier \n",
    "from sklearn.svm import SVC \n",
    "\n",
    "\n",
    "college = pd.read_csv(\"College.csv\", sep=',', header=0).drop(['Unnamed: 0'], axis=1)\n",
    "college"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "S.F.Ratio      1.566853e+01\n",
       "perc.alumni    1.535567e+02\n",
       "Terminal       2.167478e+02\n",
       "PhD            2.666086e+02\n",
       "Grad.Rate      2.950737e+02\n",
       "Top10perc      3.111825e+02\n",
       "Top25perc      3.922292e+02\n",
       "Books          2.725978e+04\n",
       "Personal       4.584258e+05\n",
       "Enroll         8.633684e+05\n",
       "Room.Board     1.202743e+06\n",
       "P.Undergrad    2.317799e+06\n",
       "Accept         6.007960e+06\n",
       "Apps           1.497846e+07\n",
       "Outstate       1.618466e+07\n",
       "F.Undergrad    2.352658e+07\n",
       "Expend         2.726687e+07\n",
       "dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1-1\n",
    "# check scale of variables\n",
    "college.var().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1-2\n",
    "# split data into training/test set\n",
    "\n",
    "y=college['Private'].astype('category').cat.codes\n",
    "X=college.loc[:, college.columns != 'Private']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state=109)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[-2.45353155e-17  1.63568770e-17 -2.78066909e-17  1.30855016e-17\n",
      "  1.63568770e-17  9.81412618e-18  3.59851293e-17  2.28996278e-17\n",
      " -9.81412618e-18 -5.72490694e-17 -1.14498139e-17  0.00000000e+00\n",
      " -1.30855016e-17 -8.17843849e-18  0.00000000e+00 -4.90706309e-18\n",
      " -2.61710032e-17]\n"
     ]
    }
   ],
   "source": [
    "# 1-3\n",
    "# normalize\n",
    "scaler = StandardScaler()  \n",
    "print(scaler.fit_transform(X_train).std(axis=0))\n",
    "X_train = scaler.transform(X_train)  \n",
    "X_test = scaler.transform(X_test) \n",
    "print(scaler.fit_transform(X_train).mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 68   8]\n",
      " [  5 153]]\n",
      "Accuracy:  0.9444444444444444\n",
      "Precision:  0.9503105590062112\n",
      "Recall:  0.9683544303797469\n"
     ]
    }
   ],
   "source": [
    "# 2-1\n",
    "\"\"\"\n",
    "Try to fit a NN model on the training data, and evaluate its performance \n",
    "on the test data. Let’s try to fit a NN with one hidden layer with 10 \n",
    "nodes and use logistic for an activation function. \n",
    "What is the test error rate? What is the test error rate if we always \n",
    "predict “Yes”? What is precision? What is recall?  What is prediction \n",
    "accuracy among the cases that are predicted to be private? How would you \n",
    "compare this result with overall rate of private college?\n",
    "\n",
    "\"\"\"\n",
    "## nn model\n",
    "mlp = MLPClassifier(activation='logistic',hidden_layer_sizes=(10), max_iter=1000)  \n",
    "mlp.fit(X_train, y_train)  \n",
    "\n",
    "  \n",
    "## predict test set \n",
    "y_pred = mlp.predict(X_test)  \n",
    "\n",
    "## confusion matrix\n",
    "print(metrics.confusion_matrix(y_test, y_pred)) \n",
    "print('Accuracy: ', metrics.accuracy_score(y_test, y_pred))\n",
    "print('Precision: ', metrics.precision_score(y_test, y_pred))\n",
    "print('Recall: ', metrics.recall_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes    565\n",
      "No     212\n",
      "Name: Private, dtype: int64\n",
      "0.7271557271557272\n"
     ]
    }
   ],
   "source": [
    "print(college['Private'].value_counts())\n",
    "print(565/(565+212))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 69   7]\n",
      " [  4 154]]\n",
      "Accuracy:  0.9529914529914529\n",
      "Precision:  0.9565217391304348\n",
      "Recall:  0.9746835443037974\n"
     ]
    }
   ],
   "source": [
    "# 2-2\n",
    "\"\"\"\n",
    "Let’s try to fit a better NN model with different number of layers and \n",
    "hidden nodes (Do some experiments on the number of layers and number of \n",
    "nodes). Also, you can try to use other activation function, e.g. \n",
    "‘identity’, ‘tanh’, ‘relu’. \n",
    "What is the test error rate? What is the test error rate if we always \n",
    "predict “Yes”? What is precision? What is recall?  What is prediction \n",
    "accuracy among the cases that are predicted to be private? How would you \n",
    "compare this result with overall rate of private college?\n",
    "\"\"\"\n",
    "\n",
    "## nn model - identity\n",
    "mlp = MLPClassifier(activation = 'identity',hidden_layer_sizes=(10,10,10), max_iter=1000)  \n",
    "mlp.fit(X_train, y_train)  \n",
    "\n",
    "  \n",
    "## predict test set \n",
    "y_pred = mlp.predict(X_test)  \n",
    "\n",
    "## confusion matrix\n",
    "print(metrics.confusion_matrix(y_test, y_pred)) \n",
    "print('Accuracy: ', metrics.accuracy_score(y_test, y_pred))\n",
    "print('Precision: ', metrics.precision_score(y_test, y_pred))\n",
    "print('Recall: ', metrics.recall_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 65  11]\n",
      " [  8 150]]\n",
      "Accuracy:  0.9188034188034188\n",
      "Precision:  0.9316770186335404\n",
      "Recall:  0.9493670886075949\n"
     ]
    }
   ],
   "source": [
    "## nn model - relu\n",
    "mlp = MLPClassifier(activation = 'relu',hidden_layer_sizes=(10,10,10), max_iter=1000)  \n",
    "mlp.fit(X_train, y_train)  \n",
    "\n",
    "  \n",
    "## predict test set \n",
    "y_pred = mlp.predict(X_test)  \n",
    "\n",
    "## confusion matrix\n",
    "print(metrics.confusion_matrix(y_test, y_pred)) \n",
    "print('Accuracy: ', metrics.accuracy_score(y_test, y_pred))\n",
    "print('Precision: ', metrics.precision_score(y_test, y_pred))\n",
    "print('Recall: ', metrics.recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 66  10]\n",
      " [  3 155]]\n",
      "Accuracy:  0.9444444444444444\n",
      "Precision:  0.9393939393939394\n",
      "Recall:  0.9810126582278481\n"
     ]
    }
   ],
   "source": [
    "# 3-1\n",
    "# kernel: linear\n",
    "svclassifier = SVC(kernel='linear')    \t## Linear SVM\n",
    "svclassifier.fit(X_train, y_train)  \n",
    "y_pred = svclassifier.predict(X_test)  \t## predict test set\n",
    "print(metrics.confusion_matrix(y_test, y_pred)) \n",
    "print('Accuracy: ', metrics.accuracy_score(y_test, y_pred))\n",
    "print('Precision: ', metrics.precision_score(y_test, y_pred))\n",
    "print('Recall: ', metrics.recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 63  13]\n",
      " [  3 155]]\n",
      "Accuracy:  93.16239316239316 %\n",
      "Precision:  92.26190476190477 %\n",
      "Recall:  98.10126582278481 %\n"
     ]
    }
   ],
   "source": [
    "# 3-2\n",
    "# kernel: rbf\n",
    "svclassifier = SVC(kernel='rbf')    \t## Linear SVM\n",
    "svclassifier.fit(X_train, y_train)  \n",
    "y_pred = svclassifier.predict(X_test)  \t## predict test set\n",
    "print(metrics.confusion_matrix(y_test, y_pred)) \n",
    "print('Accuracy: ', metrics.accuracy_score(y_test, y_pred)*100,'%')\n",
    "print('Precision: ', metrics.precision_score(y_test, y_pred)*100,'%')\n",
    "print('Recall: ', metrics.recall_score(y_test, y_pred)*100 ,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
